{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a571e495",
   "metadata": {},
   "source": [
    "# **Encoder-Decoder for Everyone**\n",
    "#### By Jashank Kshirsagar\n",
    "#### **Connect with me on LinkedIn**: [linkedin.com/in/jashank-kshirsagar](https://www.linkedin.com/in/jashank-kshirsagar/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af408eeb",
   "metadata": {},
   "source": [
    "### **Reccomended Prerequisites:**  \n",
    "To really understand what the following script does, you must first understand what an Encoder and Decoder are, as well as the architecture of a Transformer model. Come back to this script once you have read the following articles:  \n",
    "1. https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c  \n",
    "2. https://kikaben.com/transformers-encoder-decoder/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a25bc8",
   "metadata": {},
   "source": [
    "### **Required Library Installs in Terminal :**    \n",
    "pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5a8a32",
   "metadata": {},
   "source": [
    "**STEP 1: LOAD THE TOKENIZER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d425257c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jasha\\anaconda3\\envs\\jk-llm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer Loaded\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer # 'AutoTokenizer' automatically loads the correct tokenizer for the chosen model. \n",
    "# A tokenizer is what converts human text into numbers (tokens) that the model can understand.\n",
    "\n",
    "tokenizer_model_name = \"microsoft/phi-2\" # Weâ€™re selecting the 'microsoft/phi-2' tokenizer because it's small and runs well on most computers.\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_model_name)  # This line actually downloads (if not already cached) and loads the tokenizer from Hugging Faceâ€™s model hub.\n",
    "print(\"Tokenizer Loaded\")  # Simple print statement so you know the tokenizer was loaded successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3a9bec",
   "metadata": {},
   "source": [
    "**STEP 2: DEFINE YOUR INPUT TEXT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870c93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Hello, how are you today?\" #You can change this to whatever text you'd like to encode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaff124",
   "metadata": {},
   "source": [
    "**STEP 3: ENCODE THE ORIGINAL TEXT INTO NUMERIC VECTORS (TOKENS)**  \n",
    "Each number represents a word, subword or punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa08e9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Input Text: Hello, how are you today?\n",
      "Encoded Form of Input Text: [15496, 11, 703, 389, 345, 1909, 30]\n"
     ]
    }
   ],
   "source": [
    "encoded_text = tokenizer.encode(input_text)   # Converts the input text into tokens (numbers) using the loaded tokenizer.\n",
    "print(f\"Original Input Text: {input_text}\")    # Shows the text as you entered it.\n",
    "print(f\"Encoded Form of Input Text: {encoded_text}\")  # Shows the tokenized numerical representation of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5604ef",
   "metadata": {},
   "source": [
    "**STEP 4: DECODE THE NUMERIC VECTORS BACK TO TEXT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f567b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Form of Input Text: [15496, 11, 703, 389, 345, 1909, 30]\n",
      "Decoded Text Returned from Encoded form: Hello, how are you today?\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(encoded_text) # Converts tokens (numbers) back into human-readable text.\n",
    "print(f\"Encoded Form of Input Text: {encoded_text}\")  # Displays the numeric token sequence.\n",
    "print(f\"Decoded Text Returned from Encoded form: {decoded_text}\") # Shows the text reconstructed from tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017a61bb",
   "metadata": {},
   "source": [
    "### **Summary:**\n",
    "\n",
    "ðŸ”‘ In short, here's why Encoding & Decoding Matter:\n",
    " - **Encoding** turns text into numbers (tokens) the model can understand.\n",
    " - A **Model** works only on numbers, not raw text.\n",
    " - **Decoding** converts the modelâ€™s numeric output back into readable text.\n",
    " - Together this cycle lets humans talk to AI models in natural language. Simple!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jk-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
